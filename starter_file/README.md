# Classification of Wine Quality

In this project, I built two ML models to classify red and white wine quality based on several features. My first model is generated by AutoML and the second one is a pre-selected model whose parameters are hypertuned. Eventually, the results of both models will be compared.

## Dataset

### Overview
We use the following [dataset](https://www.kaggle.com/ruthgn/wine-quality-data-set-red-white-wine?select=wine-quality-white-and-red.csv) provided by Kaggle. This data set contains records related to red and white variants of the Portuguese Vinho Verde wine. It contains information from 1599 red wine samples and 4898 white wine samples. 

### Task
Features in the data set include the type of wine (either red or white wine) and metrics from objective tests (e.g. acidity levels, PH values, ABV, etc.), while the target/output variable (i.e., label) is a numerical score based on sensory dataâ€”median of at least 3 evaluations made by wine experts. Each expert graded the wine quality between 0 (very bad) and 10 (very excellent).

I use the quality as the target label that needs to be classified by the ML engine.

### Access
I uploaded the data in a google [spreadsheet](https://docs.google.com/spreadsheets/d/e/2PACX-1vQ0_ymTF3299kfZvr0KJq5JMLX7ZK4yRg9RXYTqEsMqm2eeUrABv_4MVQMzrqfw1CsbmcrnTqIluMA0/pub?output=csv) and access them via pandas (`read_csv method`).

## Automated ML
In a first step, I applied AutoML provided by AzureML to find the best model for my task. There, I used the following settings for the engine:
```
automl_settings = {
       "n_cross_validations": 5,
       "primary_metric": 'AUC_weighted',
       "enable_early_stopping": True,
       "experiment_timeout_hours": 1.0,
       "max_concurrent_iterations": 4,
       "verbosity": logging.INFO}

automl_config = AutoMLConfig(
    compute_target = compute_target,
    task='classification',
    training_data=ds,
    label_column_name='quality',
    **automl_settings)
```
As introduced above, we would like to classify the wine's quality. We, thus, specify the AutoML task as a `classification` problem with the "quality" column as the respective label to predict. Our Kaggle dataset obviously served as the training data set (here: `ds`). The specification of the `compute_target` completes the configuration.

Additionally, I also specified the settings for the AutoML experiment. As the main configuration, I decided to use the weighted Area-Under-the-Curve (i.e., arithmetic mean of the score for each class, weighted by the number of true instances in each class) that is optimized. One of the advantages (and also arguments pro AUC) is its capability to deal with data sets that might have a skewed sample distribution. It then prevents an overfitting towards single classes. For those kind of classification tasks, `AUC_weighted` is often the default setting to start with.

Furthermore, I set the number of cross validations (i.e., the number of validations to perform when user validation data is not specified) to 5. `n_cross_validations` also depends on the size of the dataset meaning the number of observations. Given the size of our data set with around 6,500 samples, five cross validations seemed as a good trade-off between runtime and accuracy.

Against the same background, I enabled the early stopping criterium. The logic applies when the score is not improving anymore while still preventing early stopping (default setting is also True). Since my maximum lab duration was limited, I started with enabling the `enable_early_stopping`. For the same reasons, I also provided an `experiment_timeout_hours` of one hour. After exceeding that maximum amount of time the experiment terminates. As mentioned above, that restriction was not binding in my case. 

Since I used a compute target with more than one node, I could also increase the `max_concurrent_iterations` from 1 to 4 increasing performance/speed when running AutoML. Remaining parameters were chosen based on default recommendations.


### Results
As shown in the figure below, the experiment took 25 minutes and completed successfully. 
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_experiment_done.PNG)

AUC (weighted) as the primary metric reached an accuracy of 86.7%. Further metrics are shown below: 
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_result1.PNG)

For the sake of completeness, I also exported some of the main characteristics/results:
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_result2.PNG)
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_confusion_matrix.PNG)

The AutoML engine assessed 37 models and the last one brought an increase to the weighted AUC.
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_model_comparison.PNG)

As shown in the jupyter notebook and also screencast, the most performant model was a Stack Ensemble than completed after only 37 seconds. In the following, I exported the best model. For further information (also on the best estimator), I kindly refer to the notebook output and/or the screencast.
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_bestmodel_studio.PNG)
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_bestmodel.PNG)

Before model selection, AutoML gave an alert in the class balancing detection.
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/automl_alerting.PNG)
To fix the balancing problem and also improve the model's results, I would combine features (e.g., through clustering algorithms) in the next iteration/run to increase class' sizes.

## Hyperparameter Tuning
For that experiment, I pre-selected a logistic regression that is a simple (and easy-to-understand) but also a powerful method when it comes to classification problems. For the hyperparameter tuning, I used the following parameters for sampling and termination:
```
early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)

param_sampling = RandomParameterSampling({'--C': uniform(0.001,0.5),"--max_iter":choice(10,100,1000,10000)})
```
Stopping policy: In that project, I chose the Bandit policy that is based on slack factor/slack amount and evaluation interval. In other words, the policy terminates the run when the primary metric breaches the slack of the most successfull run. Again, the method is rather simple and very efficient in those solution spaces. The underlying specification of the policy comes from an example provided by Microsoft (see [link](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters) for details). In that example, the early termination policy is applied at every interval when metrics are reported, starting at evaluation interval 5. Any run whose best metric is less than (1/(1+0.1) or 91% of the best performing run will be terminated.

Parameter Sampler: I chose the Random Sampling as the parameter sampling method, i.e., hyperparameters are randomly selected from the search space. One of its benefits is that it the method also supports early termination of low-performance runs. Besides that it is simple and comes with a lack of bias. ML scientists often tend to work with favorite methods and hypertune parameters. By using Random Sampling, the method starts with a rather balanced 'random' view. 

I hypertuned two parameters by including `--C` (regularization strength) and `--max_iter` (i.e., maximum number of iterations) in the configuration. With regard to regularization strength, I simulated values between 0.001 and 0.5 (uniform distribution) resulting in different penalties that usually prevent overfitting. In addition, we chose different numbers for the `max_iter` parameter from 10 to 10,000 that cover a broad range for the tuning procedure. 

Given the early termination policy and parameter sampling, I could then complete the hyperdrive configuration and submit the experiment afterwards:
```
hyperdrive_run_config = HyperDriveConfig(estimator=estimator, hyperparameter_sampling=param_sampling, policy=early_termination_policy, max_concurrent_runs=4, primary_metric_name='Accuracy',max_total_runs=30,primary_metric_goal=PrimaryMetricGoal.MAXIMIZE)
```
For the underlying estimator, I added the entry script [train.py](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/train.py).

### Results
The hyperparameter tuning completed successfully after 18 minutes. 
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/hypertune_widget_complete.PNG)
As shown below, the studio also includes the specified parameters regarding parameter sampling and termination policy.
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/hypertune_completed.PNG)

The hypertuned model reached an accuracy of only 56.15% (with Run #2), which is relatively low compared to our previously optimized AutoML model.
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/hypertune_best_runs.PNG)

Best metrics and hyperparameters are:
* Regularization Strength: 0.0797
* Max. Iterations: 1000

The complete list of metrics and hyperparameters is given below:
```
Run(Experiment: hypertuning-experiment,
Id: HD_848aab14-9147-496b-b04f-00048405bfef,
Type: hyperdrive,
Status: Completed)
run ID:  HD_848aab14-9147-496b-b04f-00048405bfef_2
best metric:  {'Regularization Strength:': 0.07970755084992351, 'Max iterations:': 1000, 'Accuracy': 0.5615384615384615}
hyperparams:  {'runId': 'HD_848aab14-9147-496b-b04f-00048405bfef_2', 'target': 'hypertuning', 'status': 'Completed', 'startTimeUtc': '2021-11-22T15:11:57.918762Z', 'endTimeUtc': '2021-11-22T15:11:59.231578Z', 'services': {}, 'warnings': [{'message': 'This run might be using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string "false"'}], 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '3d881a6d-00b8-46f6-a7a0-d11b3c75af66', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--C', '0.07970755084992351', '--max_iter', '1000'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'hypertuning', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment hypertuning-experiment Environment', 'version': 'Autosave_2021-11-22T15:07:52Z_4a1c3051', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'sklearn:0.20.3-cpu', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': 'viennaprivate.azurecr.io', 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': False}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'jarLibraries': [], 'eggLibraries': [], 'whlLibraries': [], 'pypiLibraries': [], 'rCranLibraries': [], 'mavenLibraries': [], 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None, 'autoScale': False}}, 'logFiles': {'logs/azureml/18_azureml.log': 'https://mlstrg164203.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_848aab14-9147-496b-b04f-00048405bfef_2/logs/azureml/18_azureml.log?sv=2019-07-07&sr=b&sig=7FZgbrQrDPKCGGBvn2AYZWHYoFTab%2FDshv4ITRraO4A%3D&skoid=53f8dcd1-486a-4dd0-a91f-ca80d98ba1a1&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2021-11-22T14%3A57%3A30Z&ske=2021-11-23T23%3A07%3A30Z&sks=b&skv=2019-07-07&st=2021-11-22T15%3A19%3A20Z&se=2021-11-22T23%3A29%3A20Z&sp=r'}, 'submittedBy': 'ODL_User 164203'}
```

When comparing the accuracy with the AutoML model, it becomes obvious that the hypertuning still needs some improvement. The poor accuracy indicates that I should not stick with regression (and focus on fine-tuning) in a next iteration but rather try a different model (and maybe also primary metric). Since it is a classification problem, my next pre-selection would be a random forest.

Despite its weak performance, I still registered the model and provided some properties as accuracy and the hypertuned parameters:
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/hypertune_model_registration_SDK.PNG)

## Model Deployment
Afterwards, I deployed the AutoML model via ACIWebservice that outperformed the hypertuned pre-selected model. That happened via the `deployment_config` specified as an `AciWebservice` deployment. There, I also enabled app insights (`auth_enables=True`) so that I could easily generate access keys to also query the model afterwards (see example below). `cpu_cores` and `memory_gb` were modestly set to 1 saving resources.

Besides the `deployment_config`, the deployment also requires the configuation of the inference. There, I introduced the `scoring.py` script to the endpoint that has been previously been downloaded and renamed. When querying the endpoint, that script is needed to process the request. As shown in the line below, I decided to work with the scoring script that has been provided by AzureML ([scoring.py](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/scoring.py)):
```
best_automl_run.download_file('outputs/scoring_file_v_1_0_0.py','scoring.py')
```
In the same way, I also specified the environment for the endpoint (`envFile.yml`). [Here](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/envFile.yml) you find an upload of the environment.

After defining the `deployment_config` and `inference_config`, the model has been deployed with endpoint name "aci-deployment-service" (`my_best_model` includes the optimized AutoML model).
```
Model.deploy(ws, "aci-deployment-service", [my_best_model], inference_config, deployment_config)
```
That process step took about 5 minutes. The following figure shows the successful deployment of the model (in SDK as well as in the endpoint section of the studio).
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/deployment_sdk.PNG)
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/deployment_healthy.PNG)
Both figures also show that the service is healthy and that the model can be used.

In a next step, I used two illustrative data sets to actually test the model endpoint via SDK. To do so, I built a combined data set containing two potential observations: 
```
data = {"data":
        [
          {
            "type": "red",
            "fixed acidity": 7,
            "volatile acidity": 0.27,
            "citric acid": 0.36,
            "residual sugar": 20.7,
            "chlorides": 0.045,
            "free sulfur dioxide": 45,
            "total sulfur dioxide": 170,
            "desnsity": 1.001,
            "pH": 3,
            "sulphates": 0.45,
            "alcohol": 8.8,
          },
          {
            "type": "white",
            "fixed acidity": 7,
            "volatile acidity": 0.27,
            "citric acid": 0.36,
            "residual sugar": 20.7,
            "chlorides": 0.045,
            "free sulfur dioxide": 45,
            "total sulfur dioxide": 170,
            "desnsity": 1.001,
            "pH": 3,
            "sulphates": 0.45,
            "alcohol": 8.8,
          },
      ]
    }
```
Both samples include the respective features that are afterwards processed by the deployed model to classify the wine quality.

Using the scoring URI and the endpoint's primary key, the endpoint can be triggered. That happens via a json interface (i.e., the data are first processed into a json file `data.json`). The request itself is then made via the `post` command:
```
resp = requests.post(scoring_uri, input_data, headers=headers)
```

The endpoint reacted and gave two predictions back:
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/deployment_endpoint_test.PNG)
As shown, the model classified both sample data with a quality of 6; the response is given via the json `resp.json`. The only difference between both observations was the type of wine (red vs. white wine). Ceteris paribus, the wine type itself, thus, does not change the rating of the respective wine.

For the sake of completeness, I also checked the endpoint test within the studio itself:
![plot](https://github.com/nikextens/AzureML_Capstone/blob/master/starter_file/Screenshots/deployment_test.PNG)
For that random observation, the predicted quality would be 5. Please note that the underlying data do not make any sense and I only included that step for validation reasons.

To put it in a nutshell, deployment was successful and the model could be used via SDK as well as in AzureML studio.

## Screen Recording
Following the project's structure with two scripts classifying our wine data, I created a [screencast](https://www.youtube.com/watch?v=AFK_My72Xk0) showing the configuration and application of AutoML, afterwards my hypertuned pre-selected model and, eventually, the deployment of the best model.

Enjoy watching ;).



